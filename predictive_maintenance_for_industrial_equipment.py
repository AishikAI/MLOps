# -*- coding: utf-8 -*-
"""Predictive Maintenance for industrial equipment .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iHUtw2RkdTP2HRr0XgbIN1pQnMIDp7Bh

Problem Statement: In manufacturing industries, unexpected machine failures lead to significant downtime, increased maintenance costs, and loss of productivity. While traditional maintenance practices rely on scheduled or reactive approaches, they often fail to optimize resource utilization or prevent failures effectively.

The goal of this project is to develop a predictive maintenance system using machine learning to anticipate equipment failures based on historical sensor data. By predicting whether a machine is likely to fail, the system enables proactive maintenance, reduces downtime, and improves operational efficiency.

## Import Necessary Libraries
"""

import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
import matplotlib.pyplot as plt
import numpy as np

location = pd.read_csv("ai4i2020.csv")
data = pd.DataFrame(location)
data.head(5)

data.info()

"""Let us understand what each column means and is it relevant to our analysis or not
UDI: A unique identifier for each data entry. (Irrelevant)
Product ID: Identifies the type or batch of the product being manufactured. (Irrelevant)
Type: Type of machine ("H":Heavy, "M": Medium,"L":Light)
Air temperature [K]: Surrounding temprature in Kelvin
Process temperature [K]: Temprature during machine running in Kelvin
Rotational speed [rpm]: Rotational speed of machine in RPM(Revolutions per minute)
Torque [Nm]: Torque applied to machine in Newton-metres
Tool wear [min]: Amount of wear and tear in machine in minutes
Machine failure: Indicator whether the machine failed or not (Target column)
TWF: Tool wear failure
HDF: Heat dissipation Failure
PWF: Power Failure
OSF: Over strain Failure
RNF: Random Failures

since there are no null values, let us check if there are any duplicated values in it
"""

data.duplicated().sum()

"""cool, now we can go ahead and proceed with data summary"""

data.shape

data['Machine failure'].value_counts()

"""Since Product ID and UDI are irrelevant we are dropping these columns"""

data = data.drop(columns=['UDI', 'Product ID','Air temperature [K]','Process temperature [K]','RNF'], errors='ignore')

data=data.drop(columns = ['Type'],axis=1)

data.shape
data.head()

"""### Since we have categorical values in Type column let us encode it using one hot encoding

encoder = OneHotEncoder(sparse_output=False, drop='first')
encoded_type = encoder.fit_transform(data[['Type']])
encoded_type_df = pd.DataFrame(encoded_type, columns=encoder.get_feature_names_out(['Type']))
data = data.drop(columns=['Type']).join(encoded_type_df)

### Lets normalize the numerical columns so as to ensure that each feature have equal weight
"""

scaler = StandardScaler()
numerical_features = [ 'Rotational speed [rpm]','Torque [Nm]','Tool wear [min]']
data[numerical_features] = scaler.fit_transform(data[numerical_features])

data.info()

X = data.drop(columns=['Machine failure'])
y = data['Machine failure']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"Training set size: {X_train.shape}")
print(f"Testing set size: {X_test.shape}")

"""Now that we have the data prepared, let us identify the most relevant features using RFE with the Random Forest classifier."""

rf_model_refined = RandomForestClassifier(random_state=42)

rfe = RFE(estimator=rf_model_refined, n_features_to_select=7)
rfe.fit(X_train, y_train)

selected_features = X_train.columns[rfe.support_]
print("Selected Features:", selected_features)

"""RFE iteratively removes less important features based on the model's performance.
Specifying n_features_to_select=7 ensures that only the most significant 7 features are retained, reducing dimensionality and improving model efficiency.
and from this step we get to know that ['Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'TWF',
       'HDF', 'PWF', 'OSF'] are the most important features

### Now using these important features we will train our model so that we can simplify the model and reduces noise from irrelevant features.
### This ensures the model focuses on variables that contribute the most to predicting machine failures.
"""

X_train_selected = X_train[selected_features]
X_test_selected = X_test[selected_features]

rf_model.fit(X_train_selected, y_train)

y_pred = rf_model.predict(X_test_selected)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

y_proba = rf_model.predict_proba(X_test_selected)[:, 1]
print("ROC AUC Score:", roc_auc_score(y_test, y_proba))

"""Let's see our evaluation score of our model

1. Overall Model Performance
Accuracy: 0.999
The model correctly classifies 99.9% of the test data, showcasing excellent overall performance.

Class 0 (No Failure):
Precision: 1.00 = Every instance predicted as No Failure is correct (no false positives).
Recall: 1.00 = The model successfully identifies all No Failure cases (no false negatives).
F1-Score: 1.00 = Perfect balance between precision and recall for this class.
Support: 1932 = The majority class in the dataset.

Class 1 (Failure):
Precision: 1.00 = Every instance predicted as Failure is correct.
Recall: 0.97 = 97% of actual failures are detected, but a small portion (3%) is missed.
F1-Score: 0.99 = Near-perfect performance in identifying failures.
Support: 68 = Minority class, indicating an imbalanced dataset.

ROC AUC Score: 0.9844
Measures the model's ability to distinguish between classes.
A score of 0.98 indicates excellent class separability, where the model can confidently distinguish between Failure (1) and No Failure (0).

Business Insights:

High Precision for Failures: No false alarms for failures, ensuring that resources are not wasted on unnecessary maintenance.
High Recall for Failures: Captures 97% of actual failures, minimizing the risk of missing critical issues.
Balanced Performance: Exceptional precision, recall, and F1-score across both classes.
"""

feature_importances = rf_model.feature_importances_
sorted_indices = np.argsort(feature_importances)[::-1]

plt.figure(figsize=(10, 6))
plt.bar(range(len(selected_features)), feature_importances[sorted_indices])
plt.xticks(range(len(selected_features)), selected_features[sorted_indices], rotation=45)
plt.title("Feature Importances")
plt.show()

"""### Findings

1. HDF (Heat Dissipation Failure): Accounts for the highest contribution to the model's predictions.
                                   Proper heat management is critical for machine health. Failures in heat dissipation systems are a primary cause of                                       machine breakdowns.

2. OSF (Overstrain Failure): Indicates that machines operating under high strain are prone to failure.
                             Monitoring strain levels and implementing overstrain safeguards can significantly reduce failure risks.

3. PWF (Power Failure): Highlights the importance of a stable power supply.
                        Machines require consistent power for optimal operation; power fluctuations must be minimized.

### Solutions

Heat dissipation (HDF), overstrain (OSF), and power issues (PWF) are the most critical factors affecting machine reliability.
Addressing heat and strain failures through sensors and regular maintenance could drastically improve machine uptime.
Resource allocation for monitoring HDF, OSF, and PWF should be prioritized to prevent costly downtime.

# MODEL.PKL
"""

import pickle

pickle_file_path = r"C:\Users\rajes\OneDrive\Desktop\Praxis\Term 2\MLOPS\Project\rf_model.pkl"

with open(pickle_file_path, 'wb') as file:  # 'wb' means write in binary mode
    pickle.dump(rf_model_refined, file)

print(f"Data has been pickled to {pickle_file_path}.")

"""# SCALER.PKL"""

scaler_file_path = r"C:\Users\rajes\OneDrive\Desktop\Praxis\Term 2\MLOPS\Project\scaler.pkl"

with open(scaler_file_path, 'wb') as file:
    pickle.dump(scaler, file)

print(f"Scaler has been saved to {scaler_file_path}")